<<TableOfContents(3)>>

= Intro =

Back in 2006, I hoped to catch the thief who was stripping my apricot
trees. I cobbled together a video surveillance system out of an analog
security camera, a video card, and an old PC (see see [[http://robertyu.com/wikiperdido/ObscuraLucida|Obscura Lucida]]).
It didn't work very well, but I captured amusing animal photos and 
learned a bit about home video surveillance.

Now it's 2018, and suddenly we've got a whole mess of video home
security products. Most of these products store their images in the cloud,
and they charge a monthly fee for access to useful amounts of data
(say, two weeks of video for multiple cameras). Wifi-enabled digital
cameras have also become inexpensive. The time felt ripe to revisit
home video surveillance.

I decided to roll my own.  "This will take a couple of months
of weekends and evenings," I thought. I started in later December
2017, and as I write this, January 2019 is a few weeks away.


= System Requirements =

The high-level requirements are simple:
 * My system needs to provide continuous surveillance of the front  and back of my house from multiple viewpoints; at least 5 cameras.
 * In the event that something happens, I need to be able to easily review footage from up to two weeks ago.
 * The footage needs to be of sufficient quality to identify a face from a reasonable distance.
 * For simplicity, I wanted to use as few computers as possible.

Here are the lessons I learned from my previous surveillance system:
 * Resolution is king; 1080p is a minimum useful resolution; any lower and faces at any distance appear as mere blurs.
 * The video frame rate needs to be at least 15 FPS.
 * Wifi is unreliable.  The combination of spotty coverage (at the corners of my property) and high-bandwdith content can really bring a surveillance system to its knees.
 * Motion detection is flawed yet critical.  It's flawed, because traditional motion detection algorithms simply threshold the sum of differences between frames. This works fine against a static
 background, but add a tree, a bit of breeze, and presto! you've
 got motion and false detects.  But motion detection is also
 critical, because I don't want to search through 2 weeks of
 continuous footage to find a particular event.
 * In the dark ages, hard drive storage was expensive and I had to
 put real thought into what goes into the filesystem and how long
 it would stay. Now you can buy a 2 TB external hard drive for well
 under $100. It's more important to have a usable UI which lets me
 review several weeks of footage across multiple cameras.
 * Live video ain't important.  Being able to watch in real-time is
 necessary for camera installation and debugging, but unless you've got absolutely nothing to do
 except stare at video feeds, it's not necessary.

Let's talk about the camera. Many home video surveillance vendors
these days are selling hardware in the hopes of selling a subscription
service.  Consider the Logitech Circle service: the camera (~$ 140) comes with
24 hours of storage for free (which seems largely useless); 14-day
storage is $69/year for one camera.  Storing a month of images for
five cameras is $179/year. 

Second, there are the bandwidth issues.  My DSL connection at home
supports a paltry 1 Mbps upstream, which is sufficient for a single
camera but gets dicier with additional video sources. Depending on how well the camera
handles internet congestion, this may pose a large problem.

Finally, there is the question of depending on the camera's company
for continued support. Obviously, cloud-based cameras require the company to
continue running a server for the cameras, which takes money and
effort.  What happens when the company decides that it's no longer
worthwhile?  Once upon a time, a startup called
Revolv sold a home "Smart Hub" which did something which some early
adopters found useful.  Unfortunately, the smart hub required a
back-end server to operate. In 2014 Google bought Revolv for buckets
of cash. Two years later, after the bean counters had stared deeply at
their spreadsheets, Google decided to shut down the Revolv server.
Suddenly, Revolv users were left with a $300 paperweight.  

Or consider an even simpler case: my Amcrest cameras do not require a
cloud service, but they still require external software.  There's a
mobile phone app which needs updates to track the phone's OS. I also
need to install an Amcrest-specific browser plugin to configure the
cameras, critical settings such as date/time, resolution, etc.  . What
happens when Amcrest goes out of business or they don't want to
support the latest browser?

The upshot is that I'd prefer a system which 1) doesn't really on an internet
connection for storage, and 2) doesn't require continued updates from the
manufacturer.  

= Hardware =

 * Raspberry Pi Model B: The Raspberry Pi is small, single board computer with an ARM processor,  ~$30 from Amazon.
 I'm using the Raspberry Pi as the server for storing and reviewing video and images.

 * External usb drive: Anything with 500 GB should be plenty to store 2 weeks of media.

 * Routers: The cameras have to be able to send their captures to the Raspberry

 * Cameras: Amcrest IP2M-842

= Resolution =

Here is an image of me at 1920x1080 pixels.
This is the maximum resolution for a 1080p sensor.
{{attachment:example-1080p.jpg|example 1080p|width=100%}}

Here is the same image at 1280x720 pixels.
{{attachment:example-720p.jpg|example 720p|width=100%}}

= About the Cameras =

The IP2M-842 is a digital camera in an IP66 housing (for outdoor use).
It can deliver 1080p HD video over Wifi or Ethernet, which is
important because you cannot rely on wifi coverage.  Camera
configuration is via a built-in webserver and webpage, which is
nicely full-featured.

{{attachment:cam-config.png|config page|width=50%}}

Unfortunately, the configuration webpage relies on a browser plugin to display
live video, and this plugin is not available for the Chrome browser.
There seems to be a non-browser specific client, but I never got this
to work.

The iPhone app works fairly well; it's useful for pointing the cameras
during installation. Surprisingly, the app is able to connect to my
cameras when outside my local network; I guess that's the magic of
P2P.

The viewing angle is 72 degrees, which is less than ideal. The
solution is to be extra careful with camera placement, and to use
multiple cameras. 

There is no way to tell if the camera is operating--during the day, at
least; at night, the infrared LEDs glow dimly.  A status light on the
camera would have been appreciated.

The mounting hardware consists of a mounting plate attached to the
camera via a swivel joint. It turns out the swivel is frustratingly
limited, especially when the plate is attached to a surface which is
neither perfectly vertical nor horizontal (like the angled soffit
under my eaves).  Sometimes it's simply not possible to point the
camera in the desired direction.

Fortunately, I found a 3D-printable mount on thingiverse, designed
especially for 
[[https://www.thingiverse.com/thing:2022254/#files|Amcrest Cameras]].

The mount converts an angled surface into a vertical or horizontal
surface, and makes camera-pointing somewhat easier.

{{attachment:placeholder.jpg|picture of cam with printed mount|width=200}}

Infrared illumination at night is provided by a ring of LEDs
surrounding the lens. Though I expected to buy a standalone infrared
illuminator, the built-in LEDs are adequate.  
[picture at night]

With one of my cameras, there is a defect which manifests during
infrared illumination as a halo around the image.

{{attachment:halo.jpg|image with halo|width=200}}

I would characterize Amcrest technical support as enthusiastic but
generally hapless. 

Linux support is YOYO (you're on your own)--the browser plugin
is available only for Mac or Windows, and there's no video tool 
for Linux (for converting DAV format).

The cameras come with 4 hours of storage on Amcrest's servers, though
I don't plan to use this.

The built-in software will take video and snapshots when it detects
motion [picture of motion-detection configuration] The video and
snapshots can be stored in the camera, on an SD card, or uploaded via
FTP--which is how I use it.  Images
are encoded as standard JPEG; videos, on the other hand, are encoded
in a proprietary format called DAV.  This proved to be a minor pain in the
ass. Fortunately, [[https://www.ffmpeg.org|ffmpeg]] converts this DAV format into MP4, albeit
with complaints.  The camera will also stream the video live, via
RTSP--so I can view a live feed with [[https://www.videolan.org/vlc/index.html|VLC]].

= Messing around with Open Source; Underpowered Processors =

At the start of my investigation, 
I first tried to install [[https://zoneminder.com/|ZoneMinder]]--it seemed to be the most
mature software.  Starting with a fresh install of Linux Mint 17, I
followed the "easy way" 
[[https://zoneminder.readthedocs.io/en/stable/installationguide/ubuntu.html|installation process]]--which isn't all that
easy, in terms of number of keystrokes.  There's installing Apache,
there's configuring PHP and MySQL.  This went off the rails almost
immediately, though I don't recall how. I recently tried it again and
got it working, so perhaps I was just tired. I also tried installing
the Docker image but abandoned it--the application immediately quit.

Going back to my list of free, open-source software, I next tried
[[https://shinobi.video/|Shinobi]].  Shinobi felt promising: I quickly got two webcams running with Shinobi.
After more fiddling, I eventually got Shinobi
running on an old Mac Mini server with my Amcrest wireless camera. At
this point, things started to unravel. In
particular:

 * Shinobi often hung or crashed. I would start an instance of Shinobi
 in the morning, and that evening I wouldn't be able to bring up the
 admin webpage. 

 * With a single camera running at 20 FPS and at full resolution,
 Shinobi consumed most of a single core on my aging Mac Mini.

The second issue is worth discussing in depth. Most cam surveillance
software (including Shinobi, Zone Minder, Kerberos, and Blue Iris)
accept a video stream as input. The video stream is typically JPG,  H.264 or MPEG-4. 
The surveillance software then decodes the video stream,
performs motion detection, and re-encodes the video to generate images
or video clips.  Processing a high-def video stream is a big task for
a little computer. Shinobi continuously runs ffmpeg on the video
stream, one instance per video stream. Sadly, two cameras require two instances of ffmpeg, and
Two instances of ffmpeg consumes a lot of cycles.

I borrowed an Intel Compute Stick (with an Atom processor) from work to see how it
could handle multiple cameras. Updating Linux on the Compute Stick
was immensely annoying (see
[[http://linuxiumcomau.blogspot.com/2017/06/customizing-ubuntu-isos-documentation.html|isorespin]]
).  Sadly, the stick proved to be fairly anemic, and Shinobi could handle only one camera
reliably. With two cameras, ffmpeg crashed.

Recall that I was hoping to install at least 5 cameras. At the time, I
was open to running multiple servers, but I really did not want to
provision one computer per camera!  A bit of investigation revealed
that the Raspberry Pi CPU, a Broadcom BCM2837, is actually a quad-core
ARM Cortex A53 with hardware acceleration for H.264 video encoding.  I
could see that the default version offfmpeg on the Raspberry Pi was
not making use of the accelerator.

Using a 
[[https://github.com/legotheboss/YouTube-files/wiki/(RPi)-Compile-FFmpeg-with-the-OpenMAX-H.264-GPU-acceleration|procedure from the internets]]
and
[[http://www.redhenlab.org/home/the-cognitive-core-research-topics-in-red-hen/the-barnyard/hardware-encoding-with-the-raspberry-pi|another procedure]],
I rebuilt ffmpeg from scratch to use the accelerator:
{{{#!highlight 
$ ffmpeg -encoders | grep omx
ffmpeg version git-2018-01-28-78b982d Copyright (c) 2000-2018 the FFmpeg developers
  built with gcc 6.3.0 (Raspbian 6.3.0-18+rpi1) 20170516
  configuration: --enable-gpl --enable-libx264 --enable-nonfree --enable-mmal --enable-omx --enable-omx-rpi
  ...
V..... h264_omx             OpenMAX IL H.264 video encoder (codec h264)

}}}

Brimming with anticipation, I ran Shinobi with two video streams.
Alas, it wasn't enough--the system still ran out of cycles.

I started searching Craigslist and eBay for used Core i7 servers. The Shinobi documentation
suggests that a GPU is is helpful.  :-(

= The Revelation! =

Late one evening, I sat at my computer
mulling over the problem.  I wasn't happy with Shinobi, which was 
crash-prone and cycle-hungry. I fretted over
the cost of Intel-powered servers (expensive), video stream bitrates, and 
off-the-shelf video surveillance recorders (strangely cheap) when it struck me:  why send
continuous video streams over the network at all? The cameras themselves perform motion
detection, and already generate snapshots and video clips. The server
merely needs to store snapshots and video clips!

It's obvious, looking at the price of Amcrest's video recorder ($300
for 4 wired cameras), that it's nothing more than a small processor and lots
of storage.  You really do not want your server perfoming
encoding/decoding unless the camera itself can't do it, e.g. with a
USB camera. All the cycle-consuming math can
be moved out of the server into the cameras, at the edges.

So why not set up the Raspberry Pi as a FTP server which merely
receives and stores video clips and images? Then a simple another piece
of software merely sorts the media and generates reports.
No video streams, no GPU, no decoding-motion detecting-reencoding.  

At this point, my progress proceeded in a linear fashion. It was simply a matter
of rolling up my sleeves and writing the software.

= My Home Network =

From previous experience, I knew that it would take work to get my home network
in sufficient shape for a home surveillance system. For whatever reason, it's remarkably
difficult to a good wifi at the edges of my property.

When FTPing snapshots and video, the Amcrest cameras tend to give up easily
when its network connection stutters. This results in corrupted images
and video files. 

I knew that I would need multiple wifi routers, installed in my attic and
in the garage. For the sake of simplicity, I tried to use the same brand of
router, but even this proved difficult to accomplish.
I ordered three TP Link AC1750 Archer C7 routers; when the arrived, two of the C7s were 
version 3.  The third C7 was version 4: same model name, but different processor, different
administration software.  Who does that?!  I sent it back.
In lieu of setting up a system of identical routers, I decided it would be easier to 
have a bunch of routers running identical firmware.  I bought routers which
were guaranteed to work with [[https://dd-wrt.com/|DD-WRT]], the open source
router firmware.  This proved to be a wonderful decision, because although I am
using multiple brands of wifi routers, the administration webpages all look
the same.

Between my house and my detached garage, I set up a 
[[https://wiki.dd-wrt.com/wiki/index.php/WDS_Linked_router_network|wireless hop using WDS]] 
between two routers with the same hardware.


= Rolling My Own =

I wrote the software in Python3. I call it "Panopticon."  The system is
straightforward: An FTP server and webserver run in the background.
Meanwhile, my software:
 * wakes up periodically
 * checks the FTP folder for new images and videos, uploaded by the cameras
 * adds new media files to a database (SQLlite)
 * culls old files
 * processes new media files:
   * resize images for thumbnails via ImageMagick
   * convert DAV videos to MP4 via ffmpeg
 * generates a new set of webpages
 * goes to sleep

I deliberately chose to generate only static HTML--I wanted to keep Panopticon
lightweight and secure.  The current UI is barebones, and I expect it will evolve as
I add more cameras and increase the amount of stored media.  I used Bootstrap as a front-end component library,
because it gives me built-in mobile support along with other gewgaws which I desired
(collapsing lists, sane CSS).  I wrote a teeny bit of Javascript--only where necessary, and
I washed my hands afterwards.

It turns out the video DAV format generated by the Amcrest cameras is vendor-specific, and ffmpeg often
outputs garbage when converting from DAV to MP4. This is a good reason to get a camera
which generates standard MP4 videos.

Because Shinobi often seemed to crash or hang while waiting for ffmpeg, I also
implemented a watchdog process which periodically checks Panopticon
for a pulse and reboots the system if necessary. Surprisingly, I've never
seen the watchdog have to reboot the system.

Started Apr 12, finished (approx) Nov 30.  Estimate 2.5 hours a week: 33 weeks * 2.5 = 82.5 hours.

Here's a DFD with more detail:

{{attachment:placeholder.jpg|pano DFD|width=200}}


= Images from the Panopticon =

Alley during the day (ideal illumination)

{{attachment:alley-day.jpg|alley day|width=200}}

Alley at night (infrared illumination)

{{attachment:alley-night|alley night|width=200||

Video at night

{{{#!raw
video embed object
}}}


Pano "Status" page, listing all cameras

{{attachment:status-all-cams.png|status all cams|width=200}}

Pano "Status" page with a single camera expanded

{{attachment:status-expand-cam.png|status single cam|wdith=200}}


Pano Media screen: images on the left, videos on the right, in
chronological order

{{attachment:media-page.png|camera media|width=200}}

